{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced CDR Prediction Analysis\n",
    "\n",
    "This notebook implements rigorous methodology for CDR prediction:\n",
    "1. **Age-only baselines** for both binary and multiclass models\n",
    "2. **CV-selected hyperparameters** (no hardcoding)\n",
    "3. **Calibration curves** for clinical deployment readiness\n",
    "4. **Brain volume ratios** to prove structural features add value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, roc_curve,\n",
    "    accuracy_score, cohen_kappa_score\n",
    ")\n",
    "from sklearn.calibration import calibration_curve, CalibrationDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and merge data\n",
    "df = pd.read_csv('oasis_cross-sectional.csv')\n",
    "df = df[~df['ID'].str.contains('_MR2', na=False)]  # Baseline scans only\n",
    "df = df.drop(columns=['Educ', 'SES', 'MMSE', 'eTIV', 'Delay', 'Hand'])\n",
    "\n",
    "mri_df = pd.read_csv('oasis_roi_volumes.tsv', sep='\\t')\n",
    "df = df.merge(mri_df, left_on='ID', right_on='subject_id', how='inner')\n",
    "df = df.drop(columns=['subject_id'])\n",
    "\n",
    "# Get ROI columns\n",
    "roi_columns = [col for col in df.columns if 'lh_' in col or 'rh_' in col]\n",
    "\n",
    "# Scale ROI volumes by ASF\n",
    "for col in roi_columns:\n",
    "    df[col] = df[col] * df['ASF']\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nCDR distribution:\")\n",
    "print(df['CDR'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering: Create brain volume ratios\n",
    "# These ratios may capture structural changes better than absolute volumes\n",
    "\n",
    "# Hippocampal asymmetry (left/right ratio)\n",
    "df['hippocampus_asymmetry'] = df['lh_hippocampus'] / (df['rh_hippocampus'] + 1e-6)\n",
    "\n",
    "# Entorhinal asymmetry\n",
    "df['entorhinal_asymmetry'] = df['lh_entorhinal'] / (df['rh_entorhinal'] + 1e-6)\n",
    "\n",
    "# Total hippocampal volume\n",
    "df['total_hippocampus'] = df['lh_hippocampus'] + df['rh_hippocampus']\n",
    "\n",
    "# Total entorhinal volume\n",
    "df['total_entorhinal'] = df['lh_entorhinal'] + df['rh_entorhinal']\n",
    "\n",
    "# Hippocampus to whole brain ratio (normalized)\n",
    "df['hippocampus_to_brain_ratio'] = df['total_hippocampus'] / (df['nWBV'] * 1e6)\n",
    "\n",
    "# Ventricular expansion (larger ventricles = more atrophy)\n",
    "df['total_ventricles'] = df['lh_lateral_ventricle'] + df['rh_lateral_ventricle']\n",
    "df['ventricle_to_brain_ratio'] = df['total_ventricles'] / (df['nWBV'] * 1e6)\n",
    "\n",
    "print(f\"\\nAdded ratio features:\")\n",
    "ratio_features = [\n",
    "    'hippocampus_asymmetry', 'entorhinal_asymmetry',\n",
    "    'total_hippocampus', 'total_entorhinal',\n",
    "    'hippocampus_to_brain_ratio', 'total_ventricles',\n",
    "    'ventricle_to_brain_ratio'\n",
    "]\n",
    "print(ratio_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variables\n",
    "df['CDR_binary'] = (df['CDR'] > 0).astype(int)\n",
    "\n",
    "# Fix multiclass: Convert to integer labels\n",
    "df['CDR_multiclass'] = df['CDR'].copy()\n",
    "df.loc[df['CDR'] >= 1, 'CDR_multiclass'] = 1.0  # Collapse CDR â‰¥1\n",
    "# Convert to integer categorical\n",
    "cdr_map = {0.0: 0, 0.5: 1, 1.0: 2}\n",
    "df['CDR_multiclass'] = df['CDR_multiclass'].map(cdr_map)\n",
    "\n",
    "print(f\"Binary CDR distribution:\")\n",
    "print(df['CDR_binary'].value_counts())\n",
    "print(f\"\\nMulticlass CDR distribution:\")\n",
    "print(df['CDR_multiclass'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Binary Classification: CDR=0 vs CDR>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for binary classification\n",
    "X_binary = df.drop(columns=['ID', 'CDR', 'CDR_binary', 'CDR_multiclass'])\n",
    "X_binary['M/F'] = (X_binary['M/F'] == 'M').astype(int)\n",
    "y_binary = df['CDR_binary']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_binary, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"Test set CDR=0: {sum(y_test==0)}, CDR>0: {sum(y_test==1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv_svm(X_train, y_train, X_test, y_test, model_name, param_grid, task='binary'):\n",
    "    \"\"\"\n",
    "    Perform nested cross-validation with proper hyperparameter selection.\n",
    "    Returns: best_params, cv_scores, test_predictions, trained_model\n",
    "    \"\"\"\n",
    "    outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    scoring = 'roc_auc' if task == 'binary' else 'accuracy'\n",
    "    \n",
    "    outer_scores = []\n",
    "    best_params_list = []\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"NESTED CV: {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(outer_cv.split(X_train, y_train), 1):\n",
    "        X_train_fold = X_train.iloc[train_idx]\n",
    "        X_val_fold = X_train.iloc[val_idx]\n",
    "        y_train_fold = y_train.iloc[train_idx]\n",
    "        y_val_fold = y_train.iloc[val_idx]\n",
    "        \n",
    "        # Standardize\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_val_scaled = scaler.transform(X_val_fold)\n",
    "        \n",
    "        # Inner CV: GridSearch\n",
    "        grid_search = GridSearchCV(\n",
    "            SVC(class_weight='balanced', probability=True, random_state=42),\n",
    "            param_grid=param_grid,\n",
    "            cv=inner_cv,\n",
    "            scoring=scoring,\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train_scaled, y_train_fold)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params_list.append(grid_search.best_params_)\n",
    "        \n",
    "        # Evaluate\n",
    "        if task == 'binary':\n",
    "            y_val_proba = best_model.predict_proba(X_val_scaled)[:, 1]\n",
    "            score = roc_auc_score(y_val_fold, y_val_proba)\n",
    "        else:\n",
    "            y_val_pred = best_model.predict(X_val_scaled)\n",
    "            score = accuracy_score(y_val_fold, y_val_pred)\n",
    "        \n",
    "        outer_scores.append(score)\n",
    "        print(f\"Fold {fold_idx}: {scoring}={score:.3f}, params={grid_search.best_params_}\")\n",
    "    \n",
    "    # Most common hyperparameters\n",
    "    final_params = {}\n",
    "    for param in param_grid.keys():\n",
    "        values = [p[param] for p in best_params_list]\n",
    "        final_params[param] = Counter(values).most_common(1)[0][0]\n",
    "    \n",
    "    print(f\"\\nCV {scoring}: {np.mean(outer_scores):.3f} Â± {np.std(outer_scores):.3f}\")\n",
    "    print(f\"Selected hyperparameters: {final_params}\")\n",
    "    \n",
    "    # Train final model on full training set\n",
    "    scaler_final = StandardScaler()\n",
    "    X_train_scaled = scaler_final.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_final.transform(X_test)\n",
    "    \n",
    "    final_model = SVC(\n",
    "        **final_params,\n",
    "        class_weight='balanced',\n",
    "        probability=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    final_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Test predictions\n",
    "    y_test_pred = final_model.predict(X_test_scaled)\n",
    "    y_test_proba = final_model.predict_proba(X_test_scaled)\n",
    "    \n",
    "    return final_params, outer_scores, y_test_pred, y_test_proba, final_model, scaler_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full model with brain features + ratios\n",
    "param_grid_full = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "(\n",
    "    best_params_full,\n",
    "    cv_scores_full,\n",
    "    y_test_pred_full,\n",
    "    y_test_proba_full,\n",
    "    model_full,\n",
    "    scaler_full\n",
    ") = nested_cv_svm(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    \"Full Model (Brain Features + Ratios)\",\n",
    "    param_grid_full,\n",
    "    task='binary'\n",
    ")\n",
    "\n",
    "test_auc_full = roc_auc_score(y_test, y_test_proba_full[:, 1])\n",
    "print(f\"\\nTest AUC: {test_auc_full:.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_full, target_names=['CDR=0', 'CDR>0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age-only baseline\n",
    "X_train_age = X_train[['Age']]\n",
    "X_test_age = X_test[['Age']]\n",
    "\n",
    "param_grid_age = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "(\n",
    "    best_params_age,\n",
    "    cv_scores_age,\n",
    "    y_test_pred_age,\n",
    "    y_test_proba_age,\n",
    "    model_age,\n",
    "    scaler_age\n",
    ") = nested_cv_svm(\n",
    "    X_train_age, y_train, X_test_age, y_test,\n",
    "    \"Age-Only Baseline\",\n",
    "    param_grid_age,\n",
    "    task='binary'\n",
    ")\n",
    "\n",
    "test_auc_age = roc_auc_score(y_test, y_test_proba_age[:, 1])\n",
    "print(f\"\\nTest AUC: {test_auc_age:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BINARY CLASSIFICATION COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nFull Model:\")\n",
    "print(f\"  CV AUC:   {np.mean(cv_scores_full):.3f} Â± {np.std(cv_scores_full):.3f}\")\n",
    "print(f\"  Test AUC: {test_auc_full:.3f}\")\n",
    "print(f\"  Params:   {best_params_full}\")\n",
    "\n",
    "print(f\"\\nAge-Only Baseline:\")\n",
    "print(f\"  CV AUC:   {np.mean(cv_scores_age):.3f} Â± {np.std(cv_scores_age):.3f}\")\n",
    "print(f\"  Test AUC: {test_auc_age:.3f}\")\n",
    "print(f\"  Params:   {best_params_age}\")\n",
    "\n",
    "auc_improvement = test_auc_full - test_auc_age\n",
    "rel_improvement = (auc_improvement / test_auc_age) * 100\n",
    "\n",
    "print(f\"\\nðŸ“Š Brain features add: {auc_improvement:.3f} AUC points ({rel_improvement:.1f}% improvement)\")\n",
    "\n",
    "if auc_improvement > 0.05:\n",
    "    print(\"âœ… Brain volume ratios provide meaningful improvement!\")\n",
    "elif auc_improvement > 0.02:\n",
    "    print(\"âš ï¸  Brain features provide modest improvement (2-5% range)\")\n",
    "else:\n",
    "    print(\"âš ï¸  Brain features add minimal value over age alone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration Analysis (Clinical Deployment Requirement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Full model calibration\n",
    "CalibrationDisplay.from_predictions(\n",
    "    y_test, y_test_proba_full[:, 1],\n",
    "    n_bins=10,\n",
    "    ax=axes[0],\n",
    "    name='Full Model'\n",
    ")\n",
    "axes[0].set_title('Full Model Calibration Curve\\n(Brain Features + Ratios)')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Age-only calibration\n",
    "CalibrationDisplay.from_predictions(\n",
    "    y_test, y_test_proba_age[:, 1],\n",
    "    n_bins=10,\n",
    "    ax=axes[1],\n",
    "    name='Age-Only'\n",
    ")\n",
    "axes[1].set_title('Age-Only Model Calibration Curve')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCalibration Interpretation:\")\n",
    "print(\"- Points near diagonal = well-calibrated predictions\")\n",
    "print(\"- Above diagonal = underconfident (actual rate > predicted)\")\n",
    "print(\"- Below diagonal = overconfident (actual rate < predicted)\")\n",
    "print(\"\\nFor clinical deployment, calibration is critical:\")\n",
    "print(\"- Predicted probabilities should match true risk rates\")\n",
    "print(\"- Enables informed decision-making for patient care\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Comparison\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Full model ROC\n",
    "fpr_full, tpr_full, _ = roc_curve(y_test, y_test_proba_full[:, 1])\n",
    "plt.plot(fpr_full, tpr_full, linewidth=2.5, \n",
    "         label=f'Full Model (AUC={test_auc_full:.3f})', color='blue')\n",
    "\n",
    "# Age-only ROC\n",
    "fpr_age, tpr_age, _ = roc_curve(y_test, y_test_proba_age[:, 1])\n",
    "plt.plot(fpr_age, tpr_age, linewidth=2.5, \n",
    "         label=f'Age-Only (AUC={test_auc_age:.3f})', color='orange')\n",
    "\n",
    "# Chance line\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1.5, label='Chance', alpha=0.5)\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curve Comparison: Binary CDR Classification', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multiclass Classification: CDR Severity (0 vs 0.5 vs 1+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for multiclass\n",
    "X_multi = df.drop(columns=['ID', 'CDR', 'CDR_binary', 'CDR_multiclass'])\n",
    "X_multi['M/F'] = (X_multi['M/F'] == 'M').astype(int)\n",
    "y_multi = df['CDR_multiclass']\n",
    "\n",
    "# Train/test split\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
    "    X_multi, y_multi, test_size=0.2, random_state=42, stratify=y_multi\n",
    ")\n",
    "\n",
    "print(f\"Multiclass distribution in test set:\")\n",
    "class_names = {0: 'CDR=0', 1: 'CDR=0.5', 2: 'CDRâ‰¥1'}\n",
    "for i in range(3):\n",
    "    count = (y_test_m == i).sum()\n",
    "    print(f\"  {class_names[i]}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full model multiclass\n",
    "param_grid_multi = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "(\n",
    "    best_params_multi,\n",
    "    cv_scores_multi,\n",
    "    y_test_pred_multi,\n",
    "    y_test_proba_multi,\n",
    "    model_multi,\n",
    "    scaler_multi\n",
    ") = nested_cv_svm(\n",
    "    X_train_m, y_train_m, X_test_m, y_test_m,\n",
    "    \"Full Model (Multiclass)\",\n",
    "    param_grid_multi,\n",
    "    task='multiclass'\n",
    ")\n",
    "\n",
    "test_acc_multi = accuracy_score(y_test_m, y_test_pred_multi)\n",
    "test_kappa_multi = cohen_kappa_score(y_test_m, y_test_pred_multi, weights='quadratic')\n",
    "\n",
    "print(f\"\\nTest Accuracy: {test_acc_multi:.3f}\")\n",
    "print(f\"Test Weighted Kappa: {test_kappa_multi:.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_m, y_test_pred_multi, \n",
    "                          target_names=['CDR=0', 'CDR=0.5', 'CDRâ‰¥1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age-only multiclass baseline\n",
    "X_train_age_m = X_train_m[['Age']]\n",
    "X_test_age_m = X_test_m[['Age']]\n",
    "\n",
    "param_grid_age_m = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "(\n",
    "    best_params_age_m,\n",
    "    cv_scores_age_m,\n",
    "    y_test_pred_age_m,\n",
    "    y_test_proba_age_m,\n",
    "    model_age_m,\n",
    "    scaler_age_m\n",
    ") = nested_cv_svm(\n",
    "    X_train_age_m, y_train_m, X_test_age_m, y_test_m,\n",
    "    \"Age-Only Baseline (Multiclass)\",\n",
    "    param_grid_age_m,\n",
    "    task='multiclass'\n",
    ")\n",
    "\n",
    "test_acc_age_m = accuracy_score(y_test_m, y_test_pred_age_m)\n",
    "test_kappa_age_m = cohen_kappa_score(y_test_m, y_test_pred_age_m, weights='quadratic')\n",
    "\n",
    "print(f\"\\nTest Accuracy: {test_acc_age_m:.3f}\")\n",
    "print(f\"Test Weighted Kappa: {test_kappa_age_m:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MULTICLASS CLASSIFICATION COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nFull Model:\")\n",
    "print(f\"  CV Accuracy:   {np.mean(cv_scores_multi):.3f} Â± {np.std(cv_scores_multi):.3f}\")\n",
    "print(f\"  Test Accuracy: {test_acc_multi:.3f}\")\n",
    "print(f\"  Test Kappa:    {test_kappa_multi:.3f}\")\n",
    "print(f\"  Params:        {best_params_multi}\")\n",
    "\n",
    "print(f\"\\nAge-Only Baseline:\")\n",
    "print(f\"  CV Accuracy:   {np.mean(cv_scores_age_m):.3f} Â± {np.std(cv_scores_age_m):.3f}\")\n",
    "print(f\"  Test Accuracy: {test_acc_age_m:.3f}\")\n",
    "print(f\"  Test Kappa:    {test_kappa_age_m:.3f}\")\n",
    "print(f\"  Params:        {best_params_age_m}\")\n",
    "\n",
    "acc_improvement_m = test_acc_multi - test_acc_age_m\n",
    "rel_improvement_m = (acc_improvement_m / test_acc_age_m) * 100\n",
    "\n",
    "print(f\"\\nðŸ“Š Brain features add: {acc_improvement_m:+.3f} accuracy points ({rel_improvement_m:+.1f}% change)\")\n",
    "\n",
    "if acc_improvement_m > 0.05:\n",
    "    print(\"âœ… Brain volume ratios improve severity classification!\")\n",
    "elif acc_improvement_m > 0.02:\n",
    "    print(\"âš ï¸  Brain features provide modest improvement\")\n",
    "else:\n",
    "    print(\"âš ï¸  Brain features add minimal value for severity classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Full model\n",
    "cm_full = confusion_matrix(y_test_m, y_test_pred_multi)\n",
    "sns.heatmap(cm_full, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['CDR=0', 'CDR=0.5', 'CDRâ‰¥1'],\n",
    "            yticklabels=['CDR=0', 'CDR=0.5', 'CDRâ‰¥1'])\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "axes[0].set_title(f'Full Model\\n(Accuracy={test_acc_multi:.3f})')\n",
    "\n",
    "# Age-only\n",
    "cm_age = confusion_matrix(y_test_m, y_test_pred_age_m)\n",
    "sns.heatmap(cm_age, annot=True, fmt='d', cmap='Oranges', ax=axes[1],\n",
    "            xticklabels=['CDR=0', 'CDR=0.5', 'CDRâ‰¥1'],\n",
    "            yticklabels=['CDR=0', 'CDR=0.5', 'CDRâ‰¥1'])\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "axes[1].set_title(f'Age-Only Baseline\\n(Accuracy={test_acc_age_m:.3f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" \"*20 + \"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1ï¸âƒ£  BINARY CLASSIFICATION (CDR=0 vs CDR>0)\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Full Model Test AUC:     {test_auc_full:.3f}\")\n",
    "print(f\"Age-Only Test AUC:       {test_auc_age:.3f}\")\n",
    "print(f\"Improvement:             {auc_improvement:+.3f} AUC ({rel_improvement:+.1f}%)\")\n",
    "print(f\"Selected Hyperparams:    {best_params_full}\")\n",
    "\n",
    "print(\"\\n2ï¸âƒ£  MULTICLASS CLASSIFICATION (CDR Severity)\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Full Model Test Acc:     {test_acc_multi:.3f}\")\n",
    "print(f\"Age-Only Test Acc:       {test_acc_age_m:.3f}\")\n",
    "print(f\"Improvement:             {acc_improvement_m:+.3f} ({rel_improvement_m:+.1f}%)\")\n",
    "print(f\"Selected Hyperparams:    {best_params_multi}\")\n",
    "\n",
    "print(\"\\n3ï¸âƒ£  KEY FINDINGS\")\n",
    "print(\"-\" * 70)\n",
    "print(\"âœ“ Used nested CV with proper hyperparameter selection (no hardcoding)\")\n",
    "print(\"âœ“ Added age-only baselines to quantify brain feature contribution\")\n",
    "print(\"âœ“ Included calibration curves for clinical deployment readiness\")\n",
    "print(\"âœ“ Engineered brain volume ratios (asymmetry, normalized volumes)\")\n",
    "\n",
    "print(\"\\n4ï¸âƒ£  CLINICAL DEPLOYMENT CONSIDERATIONS\")\n",
    "print(\"-\" * 70)\n",
    "print(\"â€¢ Calibration: Check curves above - well-calibrated probabilities?\")\n",
    "print(\"â€¢ Class imbalance: Note CDR>0 is minority class (~23%)\")\n",
    "print(\"â€¢ Feature importance: Consider interpretability for clinicians\")\n",
    "print(\"â€¢ Validation: External validation on different cohort recommended\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
